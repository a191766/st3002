# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
from FinMind.data import DataLoader
from datetime import datetime, timedelta, timezone, time
import traceback
import sys
import yfinance as yf

# ==========================================
# ç‰ˆæœ¬è³‡è¨Š
# ==========================================
APP_VERSION = "v1.9.1 (é™¤éŒ¯é¡¯ç¤ºç‰ˆ)"
UPDATE_LOG = """
- v1.9.0: å¼·åˆ¶æ ¡æ­£æ™‚é–“è»¸ã€‚
- v1.9.1: è§£é™¤éœé»˜å¤±æ•—ã€‚ç•¶æŠ“ä¸åˆ°æ’è¡Œæ¦œè³‡æ–™æ™‚ï¼Œæœƒæ˜ç¢ºé¡¯ç¤ºéŒ¯èª¤è¨Šæ¯ï¼Œè€Œéç•™ä¸‹ç©ºç™½ç•«é¢ã€‚
"""

# ==========================================
# åƒæ•¸èˆ‡ Token
# ==========================================
API_TOKEN = "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkYXRlIjoiMjAyNi0wMS0xNCAxOTowMDowNiIsInVzZXJfaWQiOiJcdTllYzNcdTRlYzFcdTVhMDEiLCJlbWFpbCI6ImExOTE3NjZAZ21haWwuY29tIiwiaXAiOiIifQ.JFPtMDNbxKzhl8HsxkOlA1tMlwq8y_NA6NpbRel6HCk"
TOP_N = 300              
BREADTH_THRESHOLD = 0.65
EXCLUDE_ETF_PREFIX = "00"

st.set_page_config(page_title="ç›¤ä¸­æ¬Šè­‰é€²å ´åˆ¤æ–·", layout="wide")

# ==========================================
# åŠŸèƒ½å‡½å¼
# ==========================================

def get_trading_days(api):
    """ å–å¾—äº¤æ˜“æ—¥ """
    try:
        # å˜—è©¦æŠ“ 0050 çš„æ­·å²è³‡æ–™ä¾†åˆ¤æ–·äº¤æ˜“æ—¥
        df = api.taiwan_stock_daily(stock_id="0050", start_date=(datetime.now() - timedelta(days=20)).strftime("%Y-%m-%d"))
        if df.empty:
            # å¦‚æœé€£ 0050 éƒ½æŠ“ä¸åˆ°ï¼Œå¯èƒ½æ˜¯ Token éæœŸæˆ– API æ›äº†
            st.error("âš ï¸ ç„¡æ³•å–å¾—æ­·å²äº¤æ˜“æ—¥æ­· (API å›å‚³ç©ºå€¼)ï¼Œè«‹æª¢æŸ¥ Token æˆ–ç¶²è·¯ç‹€æ…‹ã€‚")
            return []
        dates = sorted(df['date'].unique().tolist())
    except Exception as e:
        st.error(f"âš ï¸ å–å¾—äº¤æ˜“æ—¥æ­·å¤±æ•—: {e}")
        return []
    
    # å¼·åˆ¶åŠ å…¥ä»Šå¤© (è‹¥ç‚ºäº¤æ˜“æ™‚é–“)
    tw_now = datetime.now(timezone(timedelta(hours=8)))
    today_str = tw_now.strftime("%Y-%m-%d")
    current_time = tw_now.time()
    
    if 0 <= tw_now.weekday() <= 4 and current_time >= time(8, 45):
        if not dates or today_str > dates[-1]:
            dates.append(today_str)
            
    return dates

def fetch_yahoo_realtime_batch(codes):
    """ Yahoo Finance æ‰¹æ¬¡ä¸‹è¼‰ """
    if not codes: return {}, None
    
    tw_tickers = [f"{c}.TW" for c in codes]
    two_tickers = [f"{c}.TWO" for c in codes]
    all_tickers = tw_tickers + two_tickers
    
    try:
        data = yf.download(all_tickers, period="1d", group_by='ticker', progress=False, threads=True)
        realtime_map = {}
        latest_time = None
        
        if len(all_tickers) == 1:
             t = all_tickers[0]
             df = data
             if not df.empty and not df['Close'].isna().all():
                 realtime_map[t.split('.')[0]] = float(df['Close'].iloc[-1])
                 latest_time = df.index[-1]
        else:
            for t in all_tickers:
                try:
                    df = data[t]
                    if not df.empty and not df['Close'].isna().all():
                        last_price = float(df['Close'].iloc[-1])
                        last_ts = df.index[-1]
                        if latest_time is None or last_ts > latest_time:
                            latest_time = last_ts
                        realtime_map[t.split('.')[0]] = last_price
                except:
                    continue
        return realtime_map, latest_time
    except Exception as e:
        print(f"Yahoo Err: {e}")
        return {}, None

@st.cache_data(ttl=300)
def fetch_data(_api):
    all_days = get_trading_days(_api)
    if len(all_days) < 2:
        return None

    d_curr_str = all_days[-1]
    d_prev_str = all_days[-2]
    
    debug_dates = f"D={d_curr_str}, D-1={d_prev_str}"
    
    # === æ­¥é©Ÿ 1: å–å¾—ã€ŒD-1ã€çš„æ’è¡Œ ===
    try:
        df_all = _api.taiwan_stock_daily(stock_id="", start_date=d_prev_str)
    except Exception as e:
        st.error(f"âŒ API è«‹æ±‚å…¨å¸‚å ´è³‡æ–™å¤±æ•—: {e}")
        return None
    
    # å¦‚æœ D-1 æŠ“ä¸åˆ°ï¼Œå˜—è©¦å†å¾€æ¨ä¸€å¤© (D-2)
    if df_all.empty:
        st.warning(f"âš ï¸ {d_prev_str} æŸ¥ç„¡å…¨å¸‚å ´è³‡æ–™ï¼Œå˜—è©¦å›æ¨è‡³ {all_days[-3]}...")
        d_prev_str = all_days[-3]
        df_all = _api.taiwan_stock_daily(stock_id="", start_date=d_prev_str)
        
    if df_all.empty:
        # é€™è£¡å°±æ˜¯å°è‡´ç©ºç™½ç•«é¢çš„å…‡æ‰‹
        st.error(f"âŒ åš´é‡éŒ¯èª¤ï¼šé€£çºŒå…©å¤© ({all_days[-2]}, {d_prev_str}) éƒ½ç„¡æ³•å–å¾—å…¨å¸‚å ´æ’è¡Œè³‡æ–™ã€‚API å¯èƒ½ç•°å¸¸ã€‚")
        return None
        
    cols_map = {c.lower(): c for c in df_all.columns}
    def get_col(n): return df_all[cols_map.get(n.lower(), n)]
    
    try:
        df_all['MyClose'] = get_col('Close')
        df_all['MyVol'] = get_col('Volume')
        df_all['MyId'] = get_col('stock_id')
        df_all['turnover_val'] = df_all['MyClose'] * df_all['MyVol']
    except Exception as e:
        # é€™è£¡ä¹Ÿæ˜¯æ½›åœ¨çš„ç©ºç™½å…‡æ‰‹
        st.error(f"âŒ è³‡æ–™æ¬„ä½è§£æå¤±æ•—: {e}. æŠ“åˆ°çš„æ¬„ä½æœ‰: {df_all.columns.tolist()}")
        return None

    df_all['MyId'] = df_all['MyId'].astype(str)
    df_all = df_all[df_all['MyId'].str.isdigit()]  
    df_all = df_all[~df_all['MyId'].str.startswith(EXCLUDE_ETF_PREFIX)] 
    
    df_candidates = df_all.sort_values('turnover_val', ascending=False).head(TOP_N).copy()
    target_codes = df_candidates['MyId'].tolist()
    
    # === æ­¥é©Ÿ 2: Yahoo æ‰¹æ¬¡æŠ“å–å³æ™‚åƒ¹ ===
    rt_prices, last_update_time = fetch_yahoo_realtime_batch(target_codes)
    
    # === æ­¥é©Ÿ 3: é€æª”é‹ç®— ===
    results = []
    detailed_status = []
    updated_count = 0
    
    progress_bar = st.progress(0, text="æ•¸æ“šæ•´åˆä¸­...")
    
    for i, (idx, row) in enumerate(df_candidates.iterrows()):
        code = row['MyId']
        rank = i + 1
        status = "æœªçŸ¥"
        price_src = "æ­·å²å»¶ç”¨"
        
        if code in rt_prices:
            current_close = rt_prices[code]
            price_src = "Yahooå³æ™‚"
            updated_count += 1
        else:
            current_close = row['MyClose']
        
        try:
            stock_df = _api.taiwan_stock_daily(
                stock_id=code,
                start_date=(datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")
            )
            
            stock_df = stock_df[stock_df['date'] < d_curr_str]
            
            new_row = pd.DataFrame([{
                'date': d_curr_str,
                'close': current_close
            }])
            stock_df = pd.concat([stock_df, new_row], ignore_index=True)
                
            if len(stock_df) >= 6:
                stock_df['MA5'] = stock_df['close'].rolling(5).mean()
                curr_row = stock_df.iloc[-1]
                prev_row = stock_df.iloc[-2]
                
                results.append({
                    "d_curr_ok": curr_row['close'] > curr_row['MA5'],
                    "d_prev_ok": prev_row['close'] > prev_row['MA5']
                })
                status = "âœ… ç´å…¥"
            else:
                status = "âŒ å‰”é™¤ (Kç·šä¸è¶³)"
                
        except Exception as e:
            status = f"âŒ å‰”é™¤ ({str(e)})"

        detailed_status.append({
            "æ’å": rank,
            "ä»£è™Ÿ": code,
            "ç¾åƒ¹": current_close,
            "ä¾†æº": price_src,
            "ç‹€æ…‹": status
        })
        
        if i % 20 == 0:
            progress_bar.progress((i + 1) / TOP_N, text=f"è¨ˆç®—ä¸­... (å·²æ›´æ–° {updated_count} æª”)")
            
    progress_bar.empty()
    res_df = pd.DataFrame(results)
    detail_df = pd.DataFrame(detailed_status)
    
    # === æ­¥é©Ÿ 4: å¤§ç›¤æ–œç‡ ===
    slope = 0
    try:
        twii_df = _api.taiwan_stock_daily(stock_id="TAIEX", start_date=(datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d"))
        twii_df = twii_df[twii_df['date'] < d_curr_str]
        try:
            twii_rt = yf.download("^TWII", period="1d", progress=False)
            if not twii_rt.empty:
                last_twii = float(twii_rt['Close'].iloc[-1])
                new_row = pd.DataFrame([{'date': d_curr_str, 'close': last_twii}])
                twii_df = pd.concat([twii_df, new_row], ignore_index=True)
        except:
            pass
        twii_df['MA5'] = twii_df['close'].rolling(5).mean()
        slope = twii_df['MA5'].iloc[-1] - twii_df['MA5'].iloc[-2]
    except:
        pass
        
    return {
        "d_curr": d_curr_str,
        "d_prev": d_prev_str,
        "br_curr": res_df['d_curr_ok'].mean() if not res_df.empty else 0,
        "br_prev": res_df['d_prev_ok'].mean() if not res_df.empty else 0,
        "hit_curr": res_df['d_curr_ok'].sum() if not res_df.empty else 0,
        "hit_prev": res_df['d_prev_ok'].sum() if not res_df.empty else 0,
        "valid": len(res_df),
        "slope": slope,
        "detail_df": detail_df,
        "updated_count": updated_count,
        "last_time": last_update_time,
        "debug_dates": debug_dates
    }

# ==========================================
# UI
# ==========================================
def run_streamlit():
    st.title("ğŸ“ˆ ç›¤ä¸­æ¬Šè­‰é€²å ´åˆ¤æ–· (v1.9.1 é™¤éŒ¯ç‰ˆ)")

    with st.sidebar:
        st.subheader("ç³»çµ±ç‹€æ…‹")
        st.success("API Token å·²è¼‰å…¥")
        st.code(f"Version: {APP_VERSION}")
        st.markdown(UPDATE_LOG)

    api = DataLoader()
    api.login_by_token(API_TOKEN)

    if st.button("ğŸ”„ ç«‹å³é‡æ–°æ•´ç†"):
        st.cache_data.clear()

    try:
        with st.spinner("æ­£åœ¨å¼·åˆ¶æ ¡æ­£æ™‚é–“è»¸ä¸¦æŠ“å–æ•¸æ“š..."):
            data = fetch_data(api)
            
        if data is None:
            # é€™è£¡ä¸ä½¿ç”¨ st.stop()ï¼Œè€Œæ˜¯å°å‡ºè¨Šæ¯ï¼Œé¿å…ç•«é¢å…¨ç™½
            st.warning("âš ï¸ ç¨‹å¼åŸ·è¡Œå®Œç•¢ä½†æœªå›å‚³æœ‰æ•ˆæ•¸æ“šï¼Œè«‹æŸ¥çœ‹ä¸Šæ–¹æ˜¯å¦æœ‰ç´…è‰²éŒ¯èª¤è¨Šæ¯ã€‚")
        else:
            # æ­£å¸¸é¡¯ç¤ºå€
            cond1 = (data['br_curr'] >= BREADTH_THRESHOLD) and (data['br_prev'] >= BREADTH_THRESHOLD)
            cond2 = data['slope'] > 0
            final_decision = cond1 and cond2
            time_str = data['last_time'].strftime("%H:%M:%S") if data['last_time'] else "æœªçŸ¥"

            st.subheader(f"ğŸ“… æ•¸æ“šåŸºæº–æ—¥ï¼š{data['d_curr']}")
            st.caption(f"â„¹ï¸ æ™‚é–“è»¸ç¢ºèªï¼š{data['debug_dates']}")
            st.info(f"ğŸ“Š å³æ™‚æ›´æ–°æ•¸ï¼š**{data['updated_count']}** / {len(data['detail_df'])} æª” (æ™‚é–“: {time_str})")

            c1, c2, c3 = st.columns(3)
            c1.metric("ä»Šæ—¥å»£åº¦ (D)", f"{data['br_curr']:.1%}", f"{data['hit_curr']}/{data['valid']}")
            c2.metric("æ˜¨æ—¥å»£åº¦ (D-1)", f"{data['br_prev']:.1%}", f"{data['hit_prev']}/{data['valid']}")
            c3.metric("å¤§ç›¤ MA5 æ–œç‡", f"{data['slope']:.2f}", "æ­£ âœ“" if cond2 else "éæ­£ âœ—")

            st.divider()
            st.header("ğŸ’¡ é€²å ´çµè«–")
            if final_decision:
                st.success(f"âœ… çµè«–ï¼šå¯é€²å ´")
            else:
                st.error(f"â›” çµè«–ï¼šä¸å¯é€²å ´")
            
            st.dataframe(data['detail_df'], use_container_width=True, hide_index=True)

    except Exception as e:
        st.error(f"åŸ·è¡Œå‡ºéŒ¯: {e}")
        st.code(traceback.format_exc())

if __name__ == "__main__":
    if 'streamlit' in sys.modules:
        run_streamlit()
    else:
        input("æŒ‰ Enter çµæŸ...")
