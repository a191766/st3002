# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
from FinMind.data import DataLoader
from datetime import datetime, timedelta, timezone, time
import traceback
import sys
import yfinance as yf

# ==========================================
# ç‰ˆæœ¬è³‡è¨Š
# ==========================================
APP_VERSION = "v1.9.2 (æ¬„ä½åç¨±ä¿®å¾©ç‰ˆ)"
UPDATE_LOG = """
- v1.9.1: è§£é™¤éœé»˜å¤±æ•—ã€‚
- v1.9.2: ä¿®å¾©æ¬„ä½è§£æéŒ¯èª¤ã€‚é‡æ–°åŠ å…¥æ™ºæ…§å°æ‡‰é‚è¼¯ï¼Œèƒ½æ­£ç¢ºè­˜åˆ¥ 'Trading_Volume' ç‚ºæˆäº¤é‡ã€‚
"""

# ==========================================
# åƒæ•¸èˆ‡ Token
# ==========================================
API_TOKEN = "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkYXRlIjoiMjAyNi0wMS0xNCAxOTowMDowNiIsInVzZXJfaWQiOiJcdTllYzNcdTRlYzFcdTVhMDEiLCJlbWFpbCI6ImExOTE3NjZAZ21haWwuY29tIiwiaXAiOiIifQ.JFPtMDNbxKzhl8HsxkOlA1tMlwq8y_NA6NpbRel6HCk"
TOP_N = 300              
BREADTH_THRESHOLD = 0.65
EXCLUDE_ETF_PREFIX = "00"

st.set_page_config(page_title="ç›¤ä¸­æ¬Šè­‰é€²å ´åˆ¤æ–·", layout="wide")

# ==========================================
# åŠŸèƒ½å‡½å¼
# ==========================================

def get_trading_days(api):
    """ å–å¾—äº¤æ˜“æ—¥ """
    try:
        df = api.taiwan_stock_daily(stock_id="0050", start_date=(datetime.now() - timedelta(days=20)).strftime("%Y-%m-%d"))
        if df.empty:
            # å®¹éŒ¯ï¼šè‹¥æŠ“ä¸åˆ° 0050ï¼Œå›å‚³ç©ºé™£åˆ—ï¼Œè®“å¾ŒçºŒé‚è¼¯è™•ç†
            return []
        dates = sorted(df['date'].unique().tolist())
    except Exception:
        return []
    
    tw_now = datetime.now(timezone(timedelta(hours=8)))
    today_str = tw_now.strftime("%Y-%m-%d")
    current_time = tw_now.time()
    
    # åªè¦æ˜¯å¹³æ—¥ä¸”é–‹ç›¤å¾Œï¼Œå¼·åˆ¶åŠ å…¥ä»Šå¤©
    if 0 <= tw_now.weekday() <= 4 and current_time >= time(8, 45):
        if not dates or today_str > dates[-1]:
            dates.append(today_str)
            
    return dates

def smart_get_column(df, candidates):
    """ 
    æ™ºæ…§æ¬„ä½æœå°‹ï¼šä¾åºæª¢æŸ¥å€™é¸åå–®ï¼Œå›å‚³ç¬¬ä¸€å€‹å­˜åœ¨çš„æ¬„ä½ Series 
    candidates: list of strings, e.g. ['Volume', 'Trading_Volume']
    """
    cols = df.columns
    # å»ºç«‹ä¸€å€‹å…¨å°å¯«çš„å°ç…§è¡¨
    lower_map = {c.lower(): c for c in cols}
    
    for name in candidates:
        # 1. ç²¾ç¢ºæ¯”å°
        if name in cols:
            return df[name]
        # 2. ä¸åˆ†å¤§å°å¯«æ¯”å°
        if name.lower() in lower_map:
            return df[lower_map[name.lower()]]
            
    # è‹¥éƒ½æ‰¾ä¸åˆ°ï¼Œæ‹‹å‡ºè©³ç´°éŒ¯èª¤
    raise KeyError(f"æ‰¾ä¸åˆ°ç›®æ¨™æ¬„ä½ (å˜—è©¦é: {candidates})ã€‚ç¾æœ‰æ¬„ä½: {cols.tolist()}")

def fetch_yahoo_realtime_batch(codes):
    """ Yahoo Finance æ‰¹æ¬¡ä¸‹è¼‰ """
    if not codes: return {}, None
    
    tw_tickers = [f"{c}.TW" for c in codes]
    two_tickers = [f"{c}.TWO" for c in codes]
    all_tickers = tw_tickers + two_tickers
    
    try:
        # ä¸‹è¼‰ç•¶æ—¥æ•¸æ“š
        data = yf.download(all_tickers, period="1d", group_by='ticker', progress=False, threads=True)
        realtime_map = {}
        latest_time = None
        
        # å–®æª”è™•ç† (Yahoo å›å‚³æ ¼å¼ä¸åŒ)
        if len(all_tickers) == 1:
             t = all_tickers[0]
             df = data
             if not df.empty and not df['Close'].isna().all():
                 realtime_map[t.split('.')[0]] = float(df['Close'].iloc[-1])
                 latest_time = df.index[-1]
        else:
            # å¤šæª”è™•ç†
            for t in all_tickers:
                try:
                    df = data[t]
                    if not df.empty and not df['Close'].isna().all():
                        last_price = float(df['Close'].iloc[-1])
                        last_ts = df.index[-1]
                        if latest_time is None or last_ts > latest_time:
                            latest_time = last_ts
                        realtime_map[t.split('.')[0]] = last_price
                except:
                    continue
        return realtime_map, latest_time
    except Exception as e:
        print(f"Yahoo Err: {e}")
        return {}, None

@st.cache_data(ttl=300)
def fetch_data(_api):
    all_days = get_trading_days(_api)
    if len(all_days) < 2:
        st.error(f"æ­·å²è³‡æ–™ä¸è¶³ (API é€£ç·šå¯èƒ½ç•°å¸¸)ã€‚")
        return None

    d_curr_str = all_days[-1]
    d_prev_str = all_days[-2]
    
    debug_dates = f"D={d_curr_str}, D-1={d_prev_str}"
    
    # === æ­¥é©Ÿ 1: å–å¾—ã€ŒD-1ã€çš„æ’è¡Œ ===
    try:
        df_all = _api.taiwan_stock_daily(stock_id="", start_date=d_prev_str)
    except Exception as e:
        st.error(f"âŒ API è«‹æ±‚å¤±æ•—: {e}")
        return None
    
    if df_all.empty:
        # å›æ¨æ©Ÿåˆ¶ï¼šè‹¥ D-1 æ²’è³‡æ–™ï¼Œè©¦è©¦ D-2 (é¿å…é€£å‡å¾Œ API ç¼ºæ¼)
        d_prev_str = all_days[-3]
        df_all = _api.taiwan_stock_daily(stock_id="", start_date=d_prev_str)
        
    if df_all.empty:
        st.error(f"âŒ ç„¡æ³•å–å¾—å…¨å¸‚å ´æ’è¡Œè³‡æ–™ (æ—¥æœŸ: {d_prev_str})ã€‚")
        return None
        
    # === æ¬„ä½å°æ‡‰ä¿®å¾©å€ (v1.9.2) ===
    try:
        # ä½¿ç”¨ smart_get_column ä¾†æ‰¾å°æ‡‰æ¬„ä½ï¼Œæ”¯æ´ Trading_Volume
        df_all['MyClose'] = smart_get_column(df_all, ['Close', 'price', 'deal_price'])
        df_all['MyVol'] = smart_get_column(df_all, ['Volume', 'Trading_Volume', 'vol'])
        df_all['MyId'] = smart_get_column(df_all, ['stock_id', 'code', 'SecurityCode'])
        
        # è¨ˆç®—æˆäº¤å€¼
        df_all['turnover_val'] = df_all['MyClose'] * df_all['MyVol']
    except Exception as e:
        st.error(f"âŒ è³‡æ–™æ¬„ä½è§£æå¤±æ•—: {e}")
        return None

    df_all['MyId'] = df_all['MyId'].astype(str)
    df_all = df_all[df_all['MyId'].str.isdigit()]  
    df_all = df_all[~df_all['MyId'].str.startswith(EXCLUDE_ETF_PREFIX)] 
    
    df_candidates = df_all.sort_values('turnover_val', ascending=False).head(TOP_N).copy()
    target_codes = df_candidates['MyId'].tolist()
    
    # === æ­¥é©Ÿ 2: Yahoo æ‰¹æ¬¡æŠ“å–å³æ™‚åƒ¹ ===
    rt_prices, last_update_time = fetch_yahoo_realtime_batch(target_codes)
    
    # === æ­¥é©Ÿ 3: é€æª”é‹ç®— ===
    results = []
    detailed_status = []
    updated_count = 0
    
    progress_bar = st.progress(0, text="æ•¸æ“šæ•´åˆä¸­...")
    
    for i, (idx, row) in enumerate(df_candidates.iterrows()):
        code = row['MyId']
        rank = i + 1
        status = "æœªçŸ¥"
        price_src = "æ­·å²å»¶ç”¨"
        
        if code in rt_prices:
            current_close = rt_prices[code]
            price_src = "Yahooå³æ™‚"
            updated_count += 1
        else:
            current_close = row['MyClose']
        
        try:
            stock_df = _api.taiwan_stock_daily(
                stock_id=code,
                start_date=(datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")
            )
            
            # ç¢ºä¿ä¸å«ä»Šæ—¥ (é¿å… FinMind å¶çˆ¾å·è·‘å‡ºä¸å®Œæ•´çš„ä»Šæ—¥è³‡æ–™)
            stock_df = stock_df[stock_df['date'] < d_curr_str]
            
            # æ‰‹å‹•åˆæˆä»Šæ—¥ K æ£’
            new_row = pd.DataFrame([{
                'date': d_curr_str,
                'close': current_close
            }])
            stock_df = pd.concat([stock_df, new_row], ignore_index=True)
                
            if len(stock_df) >= 6:
                stock_df['MA5'] = stock_df['close'].rolling(5).mean()
                curr_row = stock_df.iloc[-1]
                prev_row = stock_df.iloc[-2]
                
                results.append({
                    "d_curr_ok": curr_row['close'] > curr_row['MA5'],
                    "d_prev_ok": prev_row['close'] > prev_row['MA5']
                })
                status = "âœ… ç´å…¥"
            else:
                status = "âŒ å‰”é™¤ (Kç·šä¸è¶³)"
                
        except Exception as e:
            status = f"âŒ å‰”é™¤ ({str(e)})"

        detailed_status.append({
            "æ’å": rank,
            "ä»£è™Ÿ": code,
            "ç¾åƒ¹": current_close,
            "ä¾†æº": price_src,
            "ç‹€æ…‹": status
        })
        
        if i % 20 == 0:
            progress_bar.progress((i + 1) / TOP_N, text=f"è¨ˆç®—ä¸­... (å·²æ›´æ–° {updated_count} æª”)")
            
    progress_bar.empty()
    res_df = pd.DataFrame(results)
    detail_df = pd.DataFrame(detailed_status)
    
    # === æ­¥é©Ÿ 4: å¤§ç›¤æ–œç‡ ===
    slope = 0
    try:
        twii_df = _api.taiwan_stock_daily(stock_id="TAIEX", start_date=(datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d"))
        twii_df = twii_df[twii_df['date'] < d_curr_str]
        try:
            twii_rt = yf.download("^TWII", period="1d", progress=False)
            if not twii_rt.empty:
                last_twii = float(twii_rt['Close'].iloc[-1])
                new_row = pd.DataFrame([{'date': d_curr_str, 'close': last_twii}])
                twii_df = pd.concat([twii_df, new_row], ignore_index=True)
        except:
            pass
        twii_df['MA5'] = twii_df['close'].rolling(5).mean()
        slope = twii_df['MA5'].iloc[-1] - twii_df['MA5'].iloc[-2]
    except:
        pass
        
    return {
        "d_curr": d_curr_str,
        "d_prev": d_prev_str,
        "br_curr": res_df['d_curr_ok'].mean() if not res_df.empty else 0,
        "br_prev": res_df['d_prev_ok'].mean() if not res_df.empty else 0,
        "hit_curr": res_df['d_curr_ok'].sum() if not res_df.empty else 0,
        "hit_prev": res_df['d_prev_ok'].sum() if not res_df.empty else 0,
        "valid": len(res_df),
        "slope": slope,
        "detail_df": detail_df,
        "updated_count": updated_count,
        "last_time": last_update_time,
        "debug_dates": debug_dates
    }

# ==========================================
# UI
# ==========================================
def run_streamlit():
    st.title("ğŸ“ˆ ç›¤ä¸­æ¬Šè­‰é€²å ´åˆ¤æ–· (v1.9.2 ä¿®å¾©ç‰ˆ)")

    with st.sidebar:
        st.subheader("ç³»çµ±ç‹€æ…‹")
        st.success("API Token å·²è¼‰å…¥")
        st.code(f"Version: {APP_VERSION}")
        st.markdown(UPDATE_LOG)

    api = DataLoader()
    api.login_by_token(API_TOKEN)

    if st.button("ğŸ”„ ç«‹å³é‡æ–°æ•´ç†"):
        st.cache_data.clear()

    try:
        with st.spinner("æ­£åœ¨å¼·åˆ¶æ ¡æ­£æ™‚é–“è»¸ä¸¦æŠ“å–æ•¸æ“š..."):
            data = fetch_data(api)
            
        if data is None:
            st.warning("âš ï¸ ç¨‹å¼åŸ·è¡Œå®Œç•¢ä½†æœªå›å‚³æœ‰æ•ˆæ•¸æ“šï¼Œè«‹æŸ¥çœ‹ä¸Šæ–¹éŒ¯èª¤è¨Šæ¯ã€‚")
        else:
            cond1 = (data['br_curr'] >= BREADTH_THRESHOLD) and (data['br_prev'] >= BREADTH_THRESHOLD)
            cond2 = data['slope'] > 0
            final_decision = cond1 and cond2
            time_str = data['last_time'].strftime("%H:%M:%S") if data['last_time'] else "æœªçŸ¥"

            st.subheader(f"ğŸ“… æ•¸æ“šåŸºæº–æ—¥ï¼š{data['d_curr']}")
            st.caption(f"â„¹ï¸ æ™‚é–“è»¸ç¢ºèªï¼š{data['debug_dates']}")
            st.info(f"ğŸ“Š å³æ™‚æ›´æ–°æ•¸ï¼š**{data['updated_count']}** / {len(data['detail_df'])} æª” (æ™‚é–“: {time_str})")

            c1, c2, c3 = st.columns(3)
            c1.metric("ä»Šæ—¥å»£åº¦ (D)", f"{data['br_curr']:.1%}", f"{data['hit_curr']}/{data['valid']}")
            c2.metric("æ˜¨æ—¥å»£åº¦ (D-1)", f"{data['br_prev']:.1%}", f"{data['hit_prev']}/{data['valid']}")
            c3.metric("å¤§ç›¤ MA5 æ–œç‡", f"{data['slope']:.2f}", "æ­£ âœ“" if cond2 else "éæ­£ âœ—")

            st.divider()
            st.header("ğŸ’¡ é€²å ´çµè«–")
            if final_decision:
                st.success(f"âœ… çµè«–ï¼šå¯é€²å ´")
            else:
                st.error(f"â›” çµè«–ï¼šä¸å¯é€²å ´")
            
            st.dataframe(data['detail_df'], use_container_width=True, hide_index=True)

    except Exception as e:
        st.error(f"åŸ·è¡Œå‡ºéŒ¯: {e}")
        st.code(traceback.format_exc())

if __name__ == "__main__":
    if 'streamlit' in sys.modules:
        run_streamlit()
    else:
        input("æŒ‰ Enter çµæŸ...")
